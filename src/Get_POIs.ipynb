{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get POIs from OSM Data via Overpass API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import overpy\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely.wkt import loads\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Johan\\PycharmProjects\\heal_paper\n"
     ]
    }
   ],
   "source": [
    "# Change working directory to parent folder\n",
    "os.chdir(\"..\")  # Move up one directory level\n",
    "\n",
    "# Check current working directory\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define function to get POIs from Overpass API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pois(area_name, key, tags, output_name):\n",
    "    \"\"\"\n",
    "    Download and process POIs from OpenStreetMap using Overpass API.\n",
    "    \n",
    "    Parameters:\n",
    "    - area_name (str): Name of the area to query (e.g., \"Heidelberg\").\n",
    "    - key (str): The key for the POIs (e.g., \"amenity\", \"shop\").\n",
    "    - tags (list): List of tag values to query (e.g., [\"hospital\", \"clinic\"]).\n",
    "    - output_name (str): Name of the output GeoJSON file (e.g., \"pois_hd_hospitals_clinics\").\n",
    "    \"\"\"\n",
    "    # Initialize Overpass API\n",
    "    api = overpy.Overpass()\n",
    "    \n",
    "    # Build query for the provided key and tags\n",
    "    tag_queries = \"\\n\".join(\n",
    "        f'node[\"{key}\"=\"{tag}\"](area.searchArea);\\nway[\"{key}\"=\"{tag}\"](area.searchArea);\\nrelation[\"{key}\"=\"{tag}\"](area.searchArea);'\n",
    "        for tag in tags\n",
    "    )\n",
    "    \n",
    "    query = f\"\"\"\n",
    "        [out:json];\n",
    "        area[\"name\"=\"{area_name}\"][\"admin_level\"=\"6\"]->.searchArea;\n",
    "        (\n",
    "          {tag_queries}\n",
    "        );\n",
    "        out center;\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute query\n",
    "    result = api.query(query)\n",
    "    \n",
    "    # Prepare data for GeoDataFrame\n",
    "    data = []\n",
    "    \n",
    "    for element in result.nodes + result.ways + result.relations:\n",
    "        name = element.tags.get('name', 'N/A')\n",
    "        category = element.tags.get(key, 'N/A')\n",
    "        all_tags = dict(element.tags)  \n",
    "        \n",
    "        if isinstance(element, overpy.Node):\n",
    "            lat, lon = element.lat, element.lon\n",
    "            osm_id = f\"node/{element.id}\"\n",
    "            element_type = 'node'\n",
    "        elif isinstance(element, overpy.Way):\n",
    "            lat, lon = element.center_lat, element.center_lon\n",
    "            osm_id = f\"way/{element.id}\"\n",
    "            element_type = 'way'\n",
    "        else:  # Relation\n",
    "            lat, lon = element.center_lat, element.center_lon\n",
    "            osm_id = f\"relation/{element.id}\"\n",
    "            element_type = 'relation'\n",
    "        \n",
    "        data.append({\n",
    "            'osm_id': osm_id,\n",
    "            'name': name,\n",
    "            'category': category,\n",
    "            'tags': all_tags,\n",
    "            'geom_type': element_type,\n",
    "            'geometry': Point(lon, lat)\n",
    "        })\n",
    "    \n",
    "    # Create GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame(data, crs=\"EPSG:4326\", geometry='geometry')\n",
    "    gdf['priority'] = gdf['geom_type'].map({'node': 0, 'way': 1, 'relation': 2})\n",
    "    gdf = gdf.sort_values(['name', 'priority'])\n",
    "    \n",
    "    # Filter nearby duplicates\n",
    "    def filter_nearby_duplicates(group):\n",
    "        if len(group) == 1:\n",
    "            return group\n",
    "        \n",
    "        # Convert to a projected CRS for accurate distance calculation\n",
    "        group_projected = group.to_crs(epsg=25832)\n",
    "        \n",
    "        # Create a 100m buffer around the first point\n",
    "        buffer = group_projected.iloc[0].geometry.buffer(100)\n",
    "        \n",
    "        # Select points that are outside this buffer\n",
    "        outside_buffer = group_projected[~group_projected.geometry.within(buffer)]\n",
    "        \n",
    "        # Combine the first point with those outside the buffer\n",
    "        result = pd.concat([group_projected.iloc[[0]], outside_buffer])\n",
    "        \n",
    "        # Convert back to original CRS\n",
    "        return result.to_crs(gdf.crs)\n",
    "    \n",
    "    gdf = gdf.groupby('name', group_keys=False).apply(filter_nearby_duplicates)\n",
    "    gdf = gdf.drop(columns=['priority'])\n",
    "    \n",
    "    # Write the GeoDataFrame to a GeoJSON file\n",
    "    output_path = Path.cwd() / 'data' / f\"{output_name}.geojson\"\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    gdf.to_file(output_path, driver='GeoJSON')\n",
    "    \n",
    "    print(f\"Data saved to {output_path}\")\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"\\nStatistics:\")\n",
    "    stats = gdf['category'].value_counts()\n",
    "    print(stats)\n",
    "    print(f\"\\nTotal number of POIs: {len(gdf)}\")\n",
    "\n",
    "    return gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to c:\\Users\\Johan\\PycharmProjects\\heal_paper\\data\\pois_hd_supermarket_osm.geojson\n",
      "\n",
      "Statistics:\n",
      "supermarket    54\n",
      "Name: category, dtype: int64\n",
      "\n",
      "Total number of POIs: 54\n",
      "Data saved to c:\\Users\\Johan\\PycharmProjects\\heal_paper\\data\\pois_hd_health_osm.geojson\n",
      "\n",
      "Statistics:\n",
      "doctors         172\n",
      "kindergarten    147\n",
      "pharmacy         38\n",
      "hospital         32\n",
      "clinic           10\n",
      "Name: category, dtype: int64\n",
      "\n",
      "Total number of POIs: 399\n"
     ]
    }
   ],
   "source": [
    "# Call function for supermarkets\n",
    "gdf_supermarkets = download_pois(\"Heidelberg\", \"shop\", [\"supermarket\"], \"pois_hd_supermarket_osm\")\n",
    "\n",
    "# Call function for hospitals, clinics, and doctors, pharmacies and kindergartens\n",
    "gdf_pois = download_pois(\"Heidelberg\", \"amenity\", [\"hospital\", \"clinic\", \"doctors\", \"pharmacy\", \"kindergarten\"], \"pois_hd_health_osm\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Access transport stops in Heidelberg via overpass API  (bus stops, train stations, tram stops)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to c:\\Users\\Johan\\PycharmProjects\\heal_paper\\data\\pois_hd_transport_osm.geojson\n",
      "\n",
      "Statistics:\n",
      "transport    356\n",
      "Name: category, dtype: int64\n",
      "\n",
      "Total number of POIs: 356\n"
     ]
    }
   ],
   "source": [
    "# Initialize Overpass API\n",
    "api = overpy.Overpass()\n",
    "\n",
    "# Build Query for Transport Stops in Heidelberg\n",
    "result = api.query(\"\"\"\n",
    "    [out:json];\n",
    "    area[\"name\"=\"Heidelberg\"][\"admin_level\"=\"6\"]->.searchArea;\n",
    "    (\n",
    "      node[\"highway\"=\"bus_stop\"](area.searchArea);\n",
    "      node[\"railway\"=\"halt\"](area.searchArea);\n",
    "      node[\"railway\"=\"station\"](area.searchArea);\n",
    "      node[\"railway\"=\"tram_stop\"](area.searchArea);\n",
    "      way[\"highway\"=\"bus_stop\"](area.searchArea);\n",
    "      way[\"railway\"=\"halt\"](area.searchArea);\n",
    "      way[\"railway\"=\"station\"](area.searchArea);\n",
    "      way[\"railway\"=\"tram_stop\"](area.searchArea);\n",
    "      relation[\"highway\"=\"bus_stop\"](area.searchArea);\n",
    "      relation[\"railway\"=\"halt\"](area.searchArea);\n",
    "      relation[\"railway\"=\"station\"](area.searchArea);\n",
    "      relation[\"railway\"=\"tram_stop\"](area.searchArea);\n",
    "    );\n",
    "    out center;\n",
    "\"\"\")\n",
    "\n",
    "# Prepare data for GeoDataFrame\n",
    "data = []\n",
    "\n",
    "for element in result.nodes + result.ways + result.relations:\n",
    "    name = element.tags.get('name', 'N/A')\n",
    "    category = (\n",
    "        element.tags.get('highway', element.tags.get('railway', 'N/A'))\n",
    "    )\n",
    "    all_tags = dict(element.tags)\n",
    "    \n",
    "    if isinstance(element, overpy.Node):\n",
    "        lat, lon = element.lat, element.lon\n",
    "        osm_id = f\"node/{element.id}\"\n",
    "        element_type = 'node'\n",
    "    elif isinstance(element, overpy.Way):\n",
    "        lat, lon = element.center_lat, element.center_lon\n",
    "        osm_id = f\"way/{element.id}\"\n",
    "        element_type = 'way'\n",
    "    else:  # Relation\n",
    "        lat, lon = element.center_lat, element.center_lon\n",
    "        osm_id = f\"relation/{element.id}\"\n",
    "        element_type = 'relation'\n",
    "    \n",
    "    data.append({\n",
    "        'osm_id': osm_id,\n",
    "        'name': name,\n",
    "        'category': 'transport',\n",
    "        'tags': all_tags,\n",
    "        'geom_type': element_type,\n",
    "        'geometry': Point(lon, lat)\n",
    "    })\n",
    "\n",
    "# Create GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(data, crs=\"EPSG:4326\", geometry='geometry')\n",
    "gdf['priority'] = gdf['geom_type'].map({'node': 0, 'way': 1, 'relation': 2})\n",
    "gdf = gdf.sort_values(['name', 'priority'])\n",
    "\n",
    "# Function to filter nearby duplicates using GeoPandas\n",
    "def filter_nearby_duplicates(group):\n",
    "    if len(group) == 1:\n",
    "        return group\n",
    "    \n",
    "    # Convert to a projected CRS for accurate distance calculation\n",
    "    group_projected = group.to_crs(epsg=25832)\n",
    "    \n",
    "    # Create a 100m buffer around the first point\n",
    "    buffer = group_projected.iloc[0].geometry.buffer(100)\n",
    "    \n",
    "    # Select points that are outside this buffer\n",
    "    outside_buffer = group_projected[~group_projected.geometry.within(buffer)]\n",
    "    \n",
    "    # Combine the first point with those outside the buffer\n",
    "    result = pd.concat([group_projected.iloc[[0]], outside_buffer])\n",
    "    \n",
    "    # Convert back to original CRS\n",
    "    return result.to_crs(gdf.crs)\n",
    "\n",
    "# Apply the filter\n",
    "gdf = gdf.groupby('name', group_keys=False).apply(filter_nearby_duplicates)\n",
    "\n",
    "# Drop the temporary 'priority' column\n",
    "gdf = gdf.drop(columns=['priority'])\n",
    "\n",
    "# Write the GeoDataFrame to a GeoJSON file\n",
    "output_path = Path.cwd() / 'data' / 'pois_hd_transport_osm.geojson'\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "gdf.to_file(output_path, driver='GeoJSON')\n",
    "\n",
    "print(f\"Data saved to {output_path}\")\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\nStatistics:\")\n",
    "stats = gdf['category'].value_counts()\n",
    "print(stats)\n",
    "print(f\"\\nTotal number of POIs: {len(gdf)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Access senior living facilites in Heidelberg via overpass API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to c:\\Users\\Johan\\PycharmProjects\\heal_paper\\data\\pois_hd_senior_facility_osm.geojson\n",
      "\n",
      "Statistics:\n",
      "senior_facility    14\n",
      "Name: category, dtype: int64\n",
      "\n",
      "Total number of POIs: 14\n"
     ]
    }
   ],
   "source": [
    "# Build query to retrieve data for senior living facilities in Heidelberg from OpenStreetMap\n",
    "api = overpy.Overpass()\n",
    "result = api.query(\"\"\"\n",
    "    [out:json];\n",
    "    area[\"name\"=\"Heidelberg\"][\"admin_level\"=\"6\"]->.searchArea;\n",
    "    (\n",
    "      node[\"amenity\"=\"retirement_home\"](area.searchArea);\n",
    "      way[\"amenity\"=\"retirement_home\"](area.searchArea);\n",
    "      relation[\"amenity\"=\"retirement_home\"](area.searchArea);\n",
    "      node[\"amenity\"=\"nursing_home\"](area.searchArea);\n",
    "      way[\"amenity\"=\"nursing_home\"](area.searchArea);\n",
    "      relation[\"amenity\"=\"nursing_home\"](area.searchArea);\n",
    "      node[\"amenity\"=\"social_facility\"][\"social_facility\"=\"nursing_home\"](area.searchArea);\n",
    "      way[\"amenity\"=\"social_facility\"][\"social_facility\"=\"nursing_home\"](area.searchArea);\n",
    "      relation[\"amenity\"=\"social_facility\"][\"social_facility\"=\"nursing_home\"](area.searchArea);\n",
    "      node[\"amenity\"=\"social_facility\"][\"social_facility\"=\"assisted_living\"](area.searchArea);\n",
    "      way[\"amenity\"=\"social_facility\"][\"social_facility\"=\"assisted_living\"](area.searchArea);\n",
    "      relation[\"amenity\"=\"social_facility\"][\"social_facility\"=\"assisted_living\"](area.searchArea);\n",
    "    );\n",
    "    out center;\n",
    "\"\"\")\n",
    "\n",
    "# Prepare data for GeoDataFrame\n",
    "data = []\n",
    "\n",
    "for element in result.nodes + result.ways + result.relations:\n",
    "    name = element.tags.get('name', 'N/A')\n",
    "    amenity_type = element.tags.get('amenity', 'N/A')\n",
    "    social_facility_type = element.tags.get('social_facility', 'N/A')\n",
    "    all_tags = dict(element.tags)\n",
    "    \n",
    "    if isinstance(element, overpy.Node):\n",
    "        lat, lon = element.lat, element.lon\n",
    "        geom_type = 'node'\n",
    "    elif isinstance(element, overpy.Way):\n",
    "        lat, lon = element.center_lat, element.center_lon\n",
    "        geom_type = 'way'\n",
    "    else:  # Relation\n",
    "        lat, lon = element.center_lat, element.center_lon\n",
    "        geom_type = 'relation'\n",
    "    \n",
    "    data.append({\n",
    "        'osm_id': element.id,\n",
    "        'name': name,\n",
    "        'category': 'senior_facility',\n",
    "        'tags': all_tags, \n",
    "        'geom_type': geom_type,\n",
    "        'geometry': Point(lon, lat)\n",
    "    })\n",
    "\n",
    "# Create GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(data, crs=\"EPSG:4326\")\n",
    "\n",
    "# Write the GeoDataFrame to a GeoJSON file\n",
    "output_path = Path.cwd() / 'data' / 'pois_hd_senior_facility_osm.geojson'\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "gdf.to_file(output_path, driver='GeoJSON')\n",
    "\n",
    "print(f\"Data saved to {output_path}\")\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\nStatistics:\")\n",
    "stats = gdf['category'].value_counts()\n",
    "print(stats)\n",
    "print(f\"\\nTotal number of POIs: {len(gdf)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combine added senior living facilities from other sources to the list of senior living facilities**\n",
    "\n",
    "Additional senior living facilities are recovered from [Office for Social Affairs and Seniors of the City of Heidelberg]([https://www.heidelberg.de/site/Heidelberg2021/get/documents_E261654398/heidelberg/Objektdatenbank/50/PDF/50_pdf_wegweiser_senioren_heidelberg.pdf), the [healthcare and career portal kliniken.de](https://www.kliniken.de/altenheim/deutschland/ort/heidelberg), the database of the [federal representation of interests for elderly and care-dependent people](https://www.biva.de/pflege-adressen/stationaer/baden-wuerttemberg/stadt-heidelberg/heidelberg/) and a Google Maps search using the tags ’Seniorenheim’, ’Altenheim’ and ’Pflegeheim’.\n",
    "\n",
    "The additional data is found in the csv file seniorenheime_hd.csv in the data folder of the repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data saved to c:\\Users\\Johan\\PycharmProjects\\heal_paper\\data\\pois_hd_senior_facility_combined.geojson\n"
     ]
    }
   ],
   "source": [
    "# Path to the CSV file\n",
    "csv_path = Path.cwd() / 'data' / 'seniorenheime_hd.csv'\n",
    "\n",
    "# Load CSV data\n",
    "csv_df = pd.read_csv(csv_path)\n",
    "\n",
    "# Convert WKT column to geometry\n",
    "csv_df['geometry'] = csv_df['WKT'].apply(loads)\n",
    "\n",
    "# Create a GeoDataFrame\n",
    "csv_gdf = gpd.GeoDataFrame(csv_df, geometry='geometry', crs=\"EPSG:4326\")\n",
    "\n",
    "# Rename columns to match the OSM GeoDataFrame schema\n",
    "csv_gdf = csv_gdf.rename(columns={\n",
    "    'Name': 'name',\n",
    "    'Beschreibung': 'tags'\n",
    "})\n",
    "csv_gdf['category'] = 'senior_facility'\n",
    "csv_gdf['osm_id'] = None  # No OSM ID for CSV entries\n",
    "csv_gdf['geom_type'] = 'node'  # Assuming all CSV entries are point geometries\n",
    "\n",
    "# Load the existing GeoJSON data\n",
    "geojson_path = Path.cwd() / 'data' / 'pois_hd_senior_facility_osm.geojson'\n",
    "osm_gdf = gpd.read_file(geojson_path)\n",
    "\n",
    "# Combine both GeoDataFrames\n",
    "combined_gdf = gpd.GeoDataFrame(pd.concat([osm_gdf, csv_gdf], ignore_index=True), crs=\"EPSG:4326\")\n",
    "\n",
    "# Drop WKT column\n",
    "combined_gdf = combined_gdf.drop(columns=['WKT'])\n",
    "\n",
    "# Save the combined GeoDataFrame to a GeoJSON file\n",
    "output_path = Path.cwd() / 'data' / 'pois_hd_senior_facility_combined.geojson'\n",
    "combined_gdf.to_file(output_path, driver='GeoJSON')\n",
    "\n",
    "print(f\"Combined data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combine all POIs (except transport) in one dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined GeoJSON saved to: data/pois_hd_osm.geojson\n",
      "\n",
      "Statistics:\n",
      "doctors            172\n",
      "kindergarten       147\n",
      "supermarket         54\n",
      "pharmacy            38\n",
      "hospital            32\n",
      "senior_facility     31\n",
      "clinic              10\n",
      "Name: category, dtype: int64\n",
      "\n",
      "Total number of POIs: 484\n"
     ]
    }
   ],
   "source": [
    "def combine_geojson_files(input_files, output_file):\n",
    "    \"\"\"\n",
    "    Combine multiple GeoJSON files into one GeoJSON file.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_files (list of str): List of paths to input GeoJSON files.\n",
    "    - output_file (str): Path to the output GeoJSON file.\n",
    "    \"\"\"\n",
    "    combined_gdf = gpd.GeoDataFrame()\n",
    "\n",
    "    for file in input_files:\n",
    "        gdf = gpd.read_file(file)\n",
    "        combined_gdf = pd.concat([combined_gdf, gdf], ignore_index=True)\n",
    "    \n",
    "    # Save combined GeoDataFrame to a new GeoJSON file\n",
    "    combined_gdf.to_file(output_file, driver=\"GeoJSON\")\n",
    "    print(f\"Combined GeoJSON saved to: {output_file}\")\n",
    "\n",
    "    # Print statistics\n",
    "    print(\"\\nStatistics:\")\n",
    "    stats = combined_gdf['category'].value_counts()\n",
    "    print(stats)\n",
    "    print(f\"\\nTotal number of POIs: {len(combined_gdf)}\")\n",
    "    \n",
    "\n",
    "# List of input GeoJSON files\n",
    "input_files = [\n",
    "    \"data/pois_hd_supermarket_osm.geojson\",\n",
    "    \"data/pois_hd_health_osm.geojson\",\n",
    "    \"data/pois_hd_senior_facility_combined.geojson\"\n",
    "]\n",
    "\n",
    "# Path for the combined GeoJSON file\n",
    "output_file = \"data/pois_hd_osm.geojson\"\n",
    "\n",
    "# Combine files\n",
    "combine_geojson_files(input_files, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoscripting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
